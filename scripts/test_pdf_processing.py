"""
Test script for PDF processing pipeline.
"""
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.processors.pdf_parser import PDFParser
from src.processors.text_chunker import TextChunker
from loguru import logger
import json


def test_pdf_processing_pipeline():
    """Test complete PDF processing pipeline."""
    logger.info("=" * 60)
    logger.info("æ¸¬è©¦ PDF è™•ç†ç®¡é“")
    logger.info("=" * 60)
    
    # Initialize processors
    parser = PDFParser()
    chunker = TextChunker(chunk_size=1000, chunk_overlap=200)
    
    # Test PDF path
    pdf_path = "data/pdfs/PMC/PMC11792735.pdf"
    
    # Step 1: Parse PDF
    logger.info("\næ­¥é©Ÿ 1: è§£æ PDF")
    parsed = parser.parse_pdf(pdf_path)
    
    if not parsed:
        logger.error("PDF è§£æå¤±æ•—")
        return False
    
    logger.success(f"âœ“ è§£ææˆåŠŸ")
    logger.info(f"  æª”æ¡ˆ: {parsed['file_name']}")
    logger.info(f"  é æ•¸: {parsed['num_pages']}")
    logger.info(f"  ç« ç¯€æ•¸: {len(parsed['structure'])}")
    logger.info(f"  å…§å®¹é•·åº¦: {len(parsed['content'])} å­—å…ƒ")
    
    # Step 2: Extract abstract
    logger.info("\næ­¥é©Ÿ 2: æå–æ‘˜è¦")
    abstract = parser.extract_abstract(parsed)
    
    if abstract:
        logger.success(f"âœ“ æ‘˜è¦æå–æˆåŠŸ")
        logger.info(f"  é•·åº¦: {len(abstract)} å­—å…ƒ")
        logger.info(f"  é è¦½: {abstract[:150]}...")
    else:
        logger.warning("âš ï¸ æœªæ‰¾åˆ°æ‘˜è¦")
    
    # Step 3: Chunk by sections
    logger.info("\næ­¥é©Ÿ 3: æŒ‰ç« ç¯€åˆ†å¡Š")
    
    if parsed['structure']:
        chunks = chunker.chunk_by_sections(
            parsed['structure'],
            metadata={
                'file_name': parsed['file_name'],
                'file_path': parsed['file_path'],
            }
        )
        logger.success(f"âœ“ åˆ†å¡ŠæˆåŠŸï¼ˆæŒ‰ç« ç¯€ï¼‰")
    else:
        # Fallback: chunkå…¨æ–‡
        logger.info("  æ²’æœ‰ç« ç¯€çµæ§‹ï¼Œä½¿ç”¨å…¨æ–‡åˆ†å¡Š")
        chunks = chunker.chunk_text(
            parsed['content'],
            metadata={
                'file_name': parsed['file_name'],
                'file_path': parsed['file_path'],
            }
        )
        logger.success(f"âœ“ åˆ†å¡ŠæˆåŠŸï¼ˆå…¨æ–‡ï¼‰")
    
    logger.info(f"  ç¸½åˆ†å¡Šæ•¸: {len(chunks)}")
    
    # Show chunk statistics
    if chunks:
        avg_chars = sum(c['char_count'] for c in chunks) / len(chunks)
        avg_words = sum(c['word_count'] for c in chunks) / len(chunks)
        
        logger.info(f"  å¹³å‡å­—å…ƒæ•¸: {avg_chars:.0f}")
        logger.info(f"  å¹³å‡å–®è©æ•¸: {avg_words:.0f}")
    
    # Step 4: Save results
    logger.info("\næ­¥é©Ÿ 4: å„²å­˜çµæœ")
    
    output_dir = Path("data/processed")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Save parsed content
    parsed_file = output_dir / f"{Path(pdf_path).stem}_parsed.json"
    with open(parsed_file, 'w', encoding='utf-8') as f:
        json.dump(parsed, f, ensure_ascii=False, indent=2)
    
    logger.success(f"âœ“ è§£æçµæœå·²å„²å­˜: {parsed_file}")
    
    # Save chunks
    chunks_file = output_dir / f"{Path(pdf_path).stem}_chunks.json"
    with open(chunks_file, 'w', encoding='utf-8') as f:
        json.dump(chunks, f, ensure_ascii=False, indent=2)
    
    logger.success(f"âœ“ åˆ†å¡Šçµæœå·²å„²å­˜: {chunks_file}")
    
    # Summary
    logger.info("\n" + "=" * 60)
    logger.info("è™•ç†ç¸½çµ")
    logger.info("=" * 60)
    logger.info(f"âœ“ PDF è§£æ: æˆåŠŸ")
    logger.info(f"âœ“ æ‘˜è¦æå–: {'æˆåŠŸ' if abstract else 'æœªæ‰¾åˆ°'}")
    logger.info(f"âœ“ æ–‡æœ¬åˆ†å¡Š: æˆåŠŸ ({len(chunks)} å€‹åˆ†å¡Š)")
    logger.info(f"âœ“ çµæœå„²å­˜: æˆåŠŸ")
    
    return True


def main():
    """Run the test."""
    logger.info("\n" + "ğŸ§ª " * 20)
    logger.info("PDF è™•ç†ç®¡é“æ¸¬è©¦")
    logger.info("ğŸ§ª " * 20 + "\n")
    
    success = test_pdf_processing_pipeline()
    
    if success:
        logger.success("\nâœ“ æ‰€æœ‰æ¸¬è©¦é€šéï¼")
        logger.info("PDF è™•ç†ç®¡é“é‹ä½œæ­£å¸¸ã€‚")
    else:
        logger.error("\nâœ— æ¸¬è©¦å¤±æ•—")


if __name__ == "__main__":
    main()
